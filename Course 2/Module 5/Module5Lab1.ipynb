{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "K_90uQsNbZyf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part A. Build a baseline model (5 marks)\n",
        "\n",
        "Use the Keras library to build a neural network with the following:\n",
        "\n",
        "- One hidden layer of 10 nodes, and a ReLU activation function\n",
        "\n",
        "- Use the adam optimizer and the mean squared error  as the loss function.\n",
        "\n",
        "1. Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the\n",
        "train_test_split\n",
        "helper function from Scikit-learn.\n",
        "\n",
        "2. Train the model on the training data using 50 epochs.\n",
        "\n",
        "3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
        "\n",
        "4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
        "\n",
        "5. Report the mean and the standard deviation of the mean squared errors."
      ],
      "metadata": {
        "id": "vSwS5JYsfnLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the CSV file\n",
        "url = \"https://cocl.us/concrete_data\"\n",
        "\n",
        "# Load the data into a pandas DataFrame\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preview the data\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPHeg_T4fuMP",
        "outputId": "a077ea28-7af0-481b-8cae-908a091be53f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
            "0   540.0                 0.0      0.0  162.0               2.5   \n",
            "1   540.0                 0.0      0.0  162.0               2.5   \n",
            "2   332.5               142.5      0.0  228.0               0.0   \n",
            "3   332.5               142.5      0.0  228.0               0.0   \n",
            "4   198.6               132.4      0.0  192.0               0.0   \n",
            "\n",
            "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
            "0            1040.0           676.0   28     79.99  \n",
            "1            1055.0           676.0   28     61.89  \n",
            "2             932.0           594.0  270     40.27  \n",
            "3             932.0           594.0  365     41.05  \n",
            "4             978.4           825.5  360     44.30  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seperate the features and target\n",
        "X = data.drop('Strength', axis=1)\n",
        "y = data['Strength']\n",
        "\n"
      ],
      "metadata": {
        "id": "ZMn50jExf_WK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_list = []\n",
        "\n",
        "for _ in range(50):\n",
        "  # 70/30 split for training and testing as per the assignment requirement\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "  # Build the Keras model\n",
        "  model = Sequential()\n",
        "\n",
        "  # Add a Dense layer with a single neuron (linear regression)\n",
        "  model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
        "  model.add(Dense(1, activation='linear'))  # Output layer for strength\n",
        "\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "  # Training the model for 50 epochs\n",
        "  model.fit(X_train, y_train, epochs=50, verbose=0)\n",
        "\n",
        "  #evaluation\n",
        "  y_pred = model.predict(X_test)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  mse_list.append(mse)\n",
        "\n",
        "mean_mse = np.mean(mse_list)\n",
        "std_mse = np.std(mse_list)"
      ],
      "metadata": {
        "id": "qJj7UXktiMoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Mean Squared Error: {mean_mse}\")\n",
        "print(f\"Standard Deviation of MSE: {std_mse}\")\n",
        "\n",
        "# pretty high mse considering the sd of strength in the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7uTkIPj9LlF",
        "outputId": "44cf4d6d-422a-4919-9d5b-57330ae8dc53"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 351.3305720319265\n",
            "Standard Deviation of MSE: 384.8557303611925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part B. Normalize the data (5 marks)\n",
        "\n",
        "Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation.\n",
        "\n",
        "How does the mean of the mean squared errors compare to that from Step A?\n",
        "\n"
      ],
      "metadata": {
        "id": "OQ1Y4e5I_n7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Im going to just use the standard scaled from sklearn\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "mse_list = []\n",
        "\n",
        "for _ in range(50):\n",
        "  # 70/30 split\n",
        "  # using x_scaled instead of unscaled data\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "  # Build the Keras model\n",
        "  model = Sequential()\n",
        "\n",
        "  # Add a Dense layer with a single neuron (linear regression)\n",
        "  model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
        "  model.add(Dense(1, activation='linear'))  # Output layer for strength\n",
        "\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "  # Training the model for 50 epochs\n",
        "  model.fit(X_train, y_train, epochs=50, verbose=0)\n",
        "\n",
        "  #evaluation\n",
        "  y_pred = model.predict(X_test)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  mse_list.append(mse)\n",
        "\n",
        "mean_mse = np.mean(mse_list)\n",
        "std_mse = np.std(mse_list)"
      ],
      "metadata": {
        "id": "xCG90QPn_tRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Mean of the Mean Squared Error: {mean_mse}\")\n",
        "\n",
        "# Still a high mean squared error\n",
        "# it is similar to the mean of the list from the models that trained on nonscaled data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnujW3TGB0zT",
        "outputId": "260dc8b7-ca6d-4c13-ab15-e43243d24e3f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of the Mean Squared Error: 357.6950670120966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C. Increate the number of epochs (5 marks)\n",
        "\n",
        "Repeat Part B but use 100 epochs this time for training.\n",
        "\n",
        "How does the mean of the mean squared errors compare to that from Step B?"
      ],
      "metadata": {
        "id": "LGgxBdxcDMH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_list = []\n",
        "\n",
        "for _ in range(50):\n",
        "  # 70/30 split\n",
        "  # using x_scaled instead of unscaled data\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "  # Build the Keras model\n",
        "  model = Sequential()\n",
        "\n",
        "  # Add a Dense layer with a single neuron (linear regression)\n",
        "  model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
        "  model.add(Dense(1, activation='linear'))  # Output layer for strength\n",
        "\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "  # Training the model for 100 epochs\n",
        "  model.fit(X_train, y_train, epochs=100, verbose=0)\n",
        "\n",
        "  #evaluation\n",
        "  y_pred = model.predict(X_test)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  mse_list.append(mse)\n",
        "\n",
        "mean_mse = np.mean(mse_list)\n",
        "std_mse = np.std(mse_list)"
      ],
      "metadata": {
        "id": "emaQWInyDLjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Mean of the Mean Squared Error: {mean_mse}\")\n",
        "# much lower mse than part b\n",
        "# might have to train a model for more epochs to see a lower error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF1-iA6YIiSi",
        "outputId": "6d0e50f8-9bc6-43ae-fcc1-fd81ced9a2a2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of the Mean Squared Error: 158.07195907918435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# D. Increase the number of hidden layers (5 marks)\n",
        "\n",
        "Repeat part B but use a neural network with the following instead:\n",
        "\n",
        "- Three hidden layers, each of 10 nodes and ReLU activation function.\n",
        "\n",
        "How does the mean of the mean squared errors compare to that from Step B?"
      ],
      "metadata": {
        "id": "Z-YPF-RYIsn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_list = []\n",
        "\n",
        "for _ in range(50):\n",
        "  # 70/30 split\n",
        "  # using x_scaled instead of unscaled data\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "  # Build the Keras model\n",
        "  model = Sequential()\n",
        "\n",
        "  # three hidden layers with 10 nodes\n",
        "  model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(1, activation='linear'))  # Output layer for strength\n",
        "\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "  # Training the model for 50 epochs\n",
        "  model.fit(X_train, y_train, epochs=50, verbose=0)\n",
        "\n",
        "  #evaluation\n",
        "  y_pred = model.predict(X_test)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  mse_list.append(mse)\n",
        "\n",
        "mean_mse = np.mean(mse_list)"
      ],
      "metadata": {
        "id": "B7RK8X-qIw7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Mean of the Mean Squared Error: {mean_mse}\")\n",
        "\n",
        "# The mean is lower than both b and c\n",
        "# The data is complex and more epochs and more neurons will be neccessary for a model to predict better"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sIxg08yLojh",
        "outputId": "bf98e8ca-59d5-4965-eeb5-422f25e20129"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of the Mean Squared Error: 124.0995156655636\n"
          ]
        }
      ]
    }
  ]
}